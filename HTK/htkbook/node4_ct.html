<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN">

<!--Converted with jLaTeX2HTML 2002 (1.62) JA patch-1.4
patched version by:  Kenshi Muto, Debian Project.
LaTeX2HTML 2002 (1.62),
original version by:  Nikos Drakos, CBLU, University of Leeds
* revised and updated by:  Marcus Hennecke, Ross Moore, Herb Swan
* with significant contributions from:
  Jens Lippmann, Marek Rouchal, Martin Wilck and others -->
<HTML>
<HEAD>
<TITLE>Contents of General Principles of HMMs</TITLE>
<META NAME="description" CONTENT="Contents of General Principles of HMMs">
<META NAME="keywords" CONTENT="htkbook">
<META NAME="resource-type" CONTENT="document">
<META NAME="distribution" CONTENT="global">

<META HTTP-EQUIV="Content-Type" CONTENT="text/html; charset=iso-8859-1">
<META NAME="Generator" CONTENT="jLaTeX2HTML v2002 JA patch-1.4">
<META HTTP-EQUIV="Content-Style-Type" CONTENT="text/css">

<LINK REL="STYLESHEET" HREF="htkbook.css">

<LINK REL="next" HREF="node5_mn.html">
<LINK REL="previous" HREF="node3_mn.html">
<LINK REL="up" HREF="node3_mn.html">
<LINK REL="next" HREF="node5_mn.html">
</HEAD>
 
<BODY bgcolor="#ffffff" text="#000000" link="#9944EE" vlink="#0000ff" alink="#00ff00">

<H1><A NAME="SECTION02110000000000000000">&#160;</A><A NAME="s:genpHMM">&#160;</A>
<BR>
General Principles of HMMs
</H1>

<P>

<P>
<DIV ALIGN="CENTER">
<A NAME="f:messencode">&#160;</A><IMG
 WIDTH="231" HEIGHT="265" ALIGN="MIDDLE" BORDER="0"
 SRC="img3.png"
 ALT="% latex2html id marker 48336
$\textstyle \parbox{50mm}{ \begin{center}\setlength...
...pter.\arabic{figctr}  Message Encoding/Decoding}
\end{center}\end{center} }$">
</DIV>

<P>
Speech recognition systems generally assume that the speech signal is
a  realisation of some message encoded as a sequence of one or more
symbols (see Fig.&nbsp;<A HREF="#_" TARGET="_top">[*]</A>). To effect the reverse
operation of recognising the underlying symbol sequence given a spoken
utterance, the continuous speech waveform is first converted to a
sequence of equally spaced discrete parameter vectors. This sequence
of parameter vectors is assumed to form an exact representation of
the speech waveform on the basis that for the duration covered by a
single vector (typically 10ms or so), the speech waveform can be
regarded as being stationary.  Although this is not strictly true, it
is  a reasonable approximation.  Typical parametric representations in
common use are smoothed spectra or linear prediction coefficients plus
various other representations derived from these.

<P>
The r&#244;le of the recogniser is to effect a mapping between  sequences
of speech vectors and the wanted underlying symbol sequences.  Two
problems make this very difficult.  Firstly, the mapping from symbols
to speech is not one-to-one since different underlying symbols can
give rise to similar speech sounds.  Furthermore, there are large
variations in the realised speech waveform due to speaker variability,
mood, environment, etc.  Secondly, the boundaries between symbols
cannot be identified explicitly from the speech waveform.  Hence, it
is not possible to treat the speech waveform as a sequence of
concatenated static patterns. 

<P>
The second problem of not knowing the word boundary locations
can be avoided by restricting the task to
isolated word recognition.  As shown in Fig.&nbsp;<A HREF="#_" TARGET="_top">[*]</A>,
this implies that the speech waveform corresponds to a single
underlying symbol (e.g. word) chosen from a fixed vocabulary.
Despite the fact that this
simpler problem is somewhat artificial, it nevertheless has 
a wide range of practical applications.
Furthermore, it serves as a good basis for 
introducing the basic ideas of HMM-based
recognition before dealing with the more complex continuous speech
case.  Hence, isolated word recognition using HMMs will be dealt
with first.

<P>

<HR>
<ADDRESS>
<A HREF=http://htk.eng.cam.ac.uk/docs/docs.shtml TARGET=_top>Back to HTK site</A><BR>See front page for HTK Authors
</ADDRESS>
</BODY>
</HTML>
