<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN">

<!--Converted with jLaTeX2HTML 2002 (1.62) JA patch-1.4
patched version by:  Kenshi Muto, Debian Project.
LaTeX2HTML 2002 (1.62),
original version by:  Nikos Drakos, CBLU, University of Leeds
* revised and updated by:  Marcus Hennecke, Ross Moore, Herb Swan
* with significant contributions from:
  Jens Lippmann, Marek Rouchal, Martin Wilck and others -->
<HTML>
<HEAD>
<TITLE>Contents of Decoder Organisation</TITLE>
<META NAME="description" CONTENT="Contents of Decoder Organisation">
<META NAME="keywords" CONTENT="htkbook">
<META NAME="resource-type" CONTENT="document">
<META NAME="distribution" CONTENT="global">

<META HTTP-EQUIV="Content-Type" CONTENT="text/html; charset=iso-8859-1">
<META NAME="Generator" CONTENT="jLaTeX2HTML v2002 JA patch-1.4">
<META HTTP-EQUIV="Content-Style-Type" CONTENT="text/css">

<LINK REL="STYLESHEET" HREF="htkbook.css">

<LINK REL="next" HREF="node170_mn.html">
<LINK REL="previous" HREF="node168_mn.html">
<LINK REL="up" HREF="node167_mn.html">
<LINK REL="next" HREF="node170_mn.html">
</HEAD>
 
<BODY bgcolor="#ffffff" text="#000000" link="#9944EE" vlink="#0000ff" alink="#00ff00">

<H1><A NAME="SECTION031020000000000000000">&#160;</A><A NAME="s:decorg">&#160;</A>
<BR>
Decoder Organisation
</H1>

<P>
The decoding process itself is performed by a set of core functions 
provided within the library module HR<SMALL>EC</SMALL><A NAME="20855">&#160;</A>.  The process
of recognising a sequence of utterances is illustrated in 
Fig.&nbsp;<A HREF="#_" TARGET="_top">[*]</A>.

<P>
<A NAME="20562">&#160;</A>
The first stage is to create a <SPAN  CLASS="textit">recogniser-instance</SPAN>.  This is
a data structure containing the compiled recognition network and
storage for storing tokens.  The point of encapsulating all of the
information and storage needed for recognition into a single object is
that HR<SMALL>EC</SMALL><A NAME="20856">&#160;</A> is re-entrant and can support 
multiple recognisers<A NAME="20566">&#160;</A>
simultaneously.  Thus, although this facility is not utilised in the
supplied recogniser HV<SMALL>ITE</SMALL><A NAME="20857">&#160;</A>, it does provide applications
developers with the capability to have multiple recognisers running
with different networks.

<P>
Once a recogniser has been created, each unknown input is 
processed by first executing a <SPAN  CLASS="textit">start recogniser</SPAN> call, and then
processing each observation one-by-one.  When all input observations
have been processed, recognition is completed by generating a lattice.
This can be saved to disk as a standard lattice format (SLF) file or
converted to a transcription.

<P>
The above decoder organisation is extremely flexible and this is
demonstrated by the HTK tool HV<SMALL>ITE</SMALL> which is a simple 
shell program designed to allow HR<SMALL>EC</SMALL> to be driven from
the command line.  

<P>
Firstly, input
control in the form of a recognition network allows three distinct modes
of operation

<P>

<P>
<DIV ALIGN="CENTER">
<A NAME="f:decflow">&#160;</A><IMG
 WIDTH="285" HEIGHT="839" ALIGN="MIDDLE" BORDER="0"
 SRC="img476.png"
 ALT="% latex2html id marker 51266
$\textstyle \parbox{62mm}{ \begin{center}\setlength...
...chapter.\arabic{figctr}  Recognition Processing}
\end{center}\end{center} }$">
</DIV>

<P>

<OL>
<LI><SPAN  CLASS="textit">Recognition</SPAN> 
<BR>
This is the conventional case in which the recognition network
is compiled from a task level word network.<A NAME="20934">&#160;</A>

<P>
</LI>
<LI><SPAN  CLASS="textit">Forced Alignment</SPAN> 
<BR>
In this case, the  recognition network
is constructed from a word level transcription (i.e. orthography)
and a dictionary. The compiled network may include optional silences
between words and pronunciation variants.  Forced alignment is often useful
during training to automatically derive phone level transcriptions.
It can also be used in automatic annotation systems.
<A NAME="20936">&#160;</A>

<P>
</LI>
<LI><SPAN  CLASS="textit">Lattice-based Rescoring</SPAN> 
<BR>
In this case, the input network is compiled from a lattice generated
during an earlier recognition run.  This mode of operation can be
extremely useful for recogniser development since rescoring can be
an order of magnitude faster than normal recognition.   The required
lattices are usually generated by a basic recogniser running with
multiple tokens, the idea being to generate a lattice containing both
the correct transcription plus a representative number of confusions.
Rescoring can then be used to quickly evaluate the performance of more 
advanced recognisers and the effectiveness of new recognition techniques.
<A NAME="20938">&#160;</A>

<P>
</LI>
</OL>

<P>
The second source of flexibility lies in the provision of multiple
tokens and recognition output
in the form of a lattice.  In addition to providing a mechanism
for rescoring, lattice output can be used as a source of multiple
hypotheses either for further recognition processing or input
to a natural language processor.  Where convenient, lattice output
can easily be converted into N-best lists.

<P>
Finally, since HR<SMALL>EC</SMALL> is explicitly driven step-by-step at the
observation level, it allows fine control over the recognition process and a
variety of traceback and on-the-fly output possibilities.

<P>
For application developers, HR<SMALL>EC</SMALL> and the HTK library modules
on which it depends can be linked directly into applications.  It 
will also be available in the form of an industry standard API.  However, 
as mentioned earlier the HTK toolkit 
also supplies a tool called HV<SMALL>ITE</SMALL> which is a shell program
designed to allow  HR<SMALL>EC</SMALL> to be driven from the command line.
The remainder of this chapter will therefore explain the various facilities
provided for recognition from the perspective of HV<SMALL>ITE</SMALL>.

<P>

<HR>
<ADDRESS>
<A HREF=http://htk.eng.cam.ac.uk/docs/docs.shtml TARGET=_top>Back to HTK site</A><BR>See front page for HTK Authors
</ADDRESS>
</BODY>
</HTML>
