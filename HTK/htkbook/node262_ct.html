<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN">

<!--Converted with jLaTeX2HTML 2002 (1.62) JA patch-1.4
patched version by:  Kenshi Muto, Debian Project.
LaTeX2HTML 2002 (1.62),
original version by:  Nikos Drakos, CBLU, University of Leeds
* revised and updated by:  Marcus Hennecke, Ross Moore, Herb Swan
* with significant contributions from:
  Jens Lippmann, Marek Rouchal, Martin Wilck and others -->
<HTML>
<HEAD>
<TITLE>Contents of Function</TITLE>
<META NAME="description" CONTENT="Contents of Function">
<META NAME="keywords" CONTENT="htkbook">
<META NAME="resource-type" CONTENT="document">
<META NAME="distribution" CONTENT="global">

<META HTTP-EQUIV="Content-Type" CONTENT="text/html; charset=iso-8859-1">
<META NAME="Generator" CONTENT="jLaTeX2HTML v2002 JA patch-1.4">
<META HTTP-EQUIV="Content-Style-Type" CONTENT="text/css">

<LINK REL="STYLESHEET" HREF="htkbook.css">

<LINK REL="next" HREF="node263_mn.html">
<LINK REL="previous" HREF="node261_mn.html">
<LINK REL="up" HREF="node261_mn.html">
<LINK REL="next" HREF="node263_mn.html">
</HEAD>
 
<BODY bgcolor="#ffffff" text="#000000" link="#9944EE" vlink="#0000ff" alink="#00ff00">

<H2><A NAME="SECTION05161000000000000000">&#160;</A><A NAME="s:HERest-Function">&#160;</A>
<BR>
Function
</H2>

<P>
<A NAME="26299">&#160;</A> This program is used to perform a
single re-estimation of the parameters of a set of HMMs, or linear
transforms, using an <EM>embedded training</EM> version of the Baum-Welch
algorithm.  Training data consists of one or more utterances each of
which has a transcription in the form of a standard label file
(segment boundaries are ignored).  For each training utterance, a
composite model is effectively synthesised by concatenating the
phoneme models given by the transcription.  Each phone model has the
same set of accumulators allocated to it as are used in HRest but in
HER<SMALL>EST</SMALL> they are updated simultaneously by performing a
standard Baum-Welch pass over each training utterance using the
composite model.

<P>
HER<SMALL>EST</SMALL> is intended to operate on HMMs with initial parameter values 
estimated by HInit/HRest.
HER<SMALL>EST</SMALL> supports multiple mixture Gaussians, discrete and tied-mixture
HMMs, multiple data streams, parameter tying within and between models, and
full or diagonal covariance matrices. HER<SMALL>EST</SMALL> also supports tee-models
(see section&nbsp;<A HREF="node109_ct.html#s:teemods">7.8</A>), for handling optional silence and non-speech
sounds. These may be placed between the units (typically words or phones)
listed in the transcriptions but they cannot be used at the start or end of a
transcription. Furthermore, chains of tee-models are not permitted.

<P>
HER<SMALL>EST</SMALL> includes features to allow parallel operation where a network
of processors is available. When the training set is large, it can be split into separate chunks that are processed in parallel on multiple machines/processors, consequently speeding up the training process. 

<P>
Like all re-estimation tools, HER<SMALL>EST</SMALL> allows a floor to be set on
each individual variance by defining a variance floor macro for each data
stream (see chapter&nbsp;<A HREF="node112_ct.html#c:Training">8</A>).  The configuration variable <TT>VARFLOORPERCENTILE</TT> allows the same thing to be done in a different way
which appears to improve recognition results.  By setting this to e.g. 20,
the variances from each dimension are floored to the 20th percentile of the
distribution of variances for that dimensioon.

<P>
HER<SMALL>EST</SMALL> supports two specific methods for initilisation of
model parameters , <SPAN  CLASS="textit">single pass retraining</SPAN> and <SPAN  CLASS="textit">2-model
  reestimation</SPAN>.

<P>
<SPAN  CLASS="textit">Single pass retraining</SPAN> is useful when the parameterisation of
the front-end (e.g. from MFCC to PLP coefficients) is to be modified.
Given a set of well-trained models, a set of new models using a
different parameterisation of the training data can be generated in a
single pass.  This is done by computing the forward and backward
probabilities using the original well-trained models and the original
training data, but then switching to a new set of training data to
compute the new parameter estimates.

<P>
In <SPAN  CLASS="textit">2-model re-estimation</SPAN> one model set can be used to obtain
the forward backward probablilites which then are used to update the
parameters of another model set. Contrary to <SPAN  CLASS="textit">single pass
  retraining</SPAN> the two model sets are not required to be tied in the
same fashion.  This is particulary useful for training of single
mixture models prior to decision-tree based state clustering. The use
of 2-model re-estimation in HER<SMALL>EST</SMALL> is triggered by setting the
config variables <TT>ALIGNMODELMMF</TT> or <TT>ALIGNMODELDIR</TT> and <TT>  ALIGNMODELEXT</TT> together with <TT>ALIGNHMMLIST</TT> (see section <A HREF="node119_ct.html#s:twomodel">8.7</A>).
As the model list can differ for the alignment model set a seperate set of
input transforms may be specified using the <TT>ALIGNXFORMDIR</TT> and
<TT>ALIGNXFORMEXT</TT>. 

<P>
HER<SMALL>EST</SMALL> for updating model parameters operates in two distinct stages. 

<P>

<OL>
<LI>In the first stage, one of the following two options applies
 
<OL>
<LI>Each input data file contains training data which is 
    processed and the accumulators for state occupation, 
    state transition, means and variances are updated.

<P>
</LI>
<LI>Each data file contains a dump of the accumulators
    produced by previous runs of the program.  These
    are read in and added together to form a single set
    of accumulators.
  
</LI>
</OL>

<P>
</LI>
<LI>In the second stage, one of the following options applies
  
<OL>
<LI>The accumulators are used to calculate new 
         estimates for the HMM parameters.
</LI>
<LI>The accumulators are dumped into a file.
  
</LI>
</OL>
</LI>
</OL>

<P>
Thus, on a single processor the default combination 1(a) and 2(a) would
be used.  However, if N processors are available then the 
training data would be split into N equal groups and HER<SMALL>EST</SMALL> would
be set to process one data set on each processor using the combination
1(a) and 2(b). 
When all processors had finished, the 
program would then be run again using the combination 1(b) and 2(a)
to load in the partial accumulators created by the N processors
and do the final parameter re-estimation.  The choice of which combination
of operations HER<SMALL>EST</SMALL> will perform is governed by the <TT>-p</TT> option
switch as described below.

<P>
As a further performance optimisation, HER<SMALL>EST</SMALL> will also prune the
<SPAN CLASS="MATH"><IMG
 WIDTH="14" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img165.png"
 ALT="$ \alpha$"></SPAN> and <SPAN CLASS="MATH"><IMG
 WIDTH="14" HEIGHT="29" ALIGN="MIDDLE" BORDER="0"
 SRC="img288.png"
 ALT="$ \beta$"></SPAN> matrices.  By this means, a factor of 3 to 5
speed improvement and a similar reduction in memory requirements can be
achieved with negligible effects on training performance (see the <TT>-t</TT> option below).  

<P>
HER<SMALL>EST</SMALL> is able to make use of, and estimate, linear
transformations for model adaptation. There are three types of linear
transform that are made use in HER<SMALL>EST</SMALL>.

<UL>
<LI><I>Input transform</I>: the input transform is used to determine
the forward-backward probabilities, hence the component posteriors, for 
estimating model and transform 
</LI>
<LI><I>Output transform</I>: the output transform is generated when the 
<TT>-u</TT> option is set to <TT>a</TT>. The transform will be stored in the 
current directory, or the directory specified by the <TT>-K</TT> option
and optionally the transform extension.
</LI>
<LI><I>Parent transform</I>: the parent transform determines the 
model, or features, on which the model set or transform is to be 
generated. For transform estimation this allows <EM>cascades</EM> of transforms
to be used to adapt the model parameters. For model estimation this 
supports <EM>speaker adaptive training</EM>. Note the current implementation 
only supports adaptove training with CMLLR. Any parent transform can be
used when generating transforms.
</LI>
</UL>
When input or parent transforms are specified the transforms may 
physically be stored in multple diirectories. Which transform to be used 
is determined in the following search order:
order is used.

<OL>
<LI>Any loaded macro that matches the transform (and its' extension) name.
</LI>
<LI>If it is a parent transform, the directory specified with the 
<TT>-E</TT> option.
</LI>
<LI>The list of directories specified with the <TT>-J</TT> option.
The directories are searched in the order that they are specified
in the command line.
</LI>
</OL>
As the search order above looks for loaded macros first it is 
recommended that unique extensions are specified for each set of
transforms generated. Transforms may either be stored in 
a single TMF. These TMFs may be loaded using the <TT>-H</TT> option.
When macros are specified for the regression class trees and 
the base classes the following search order is used

<OL>
<LI>Any loaded macro that matches the macro name.
</LI>
<LI>The path specified by the configuration variable.
</LI>
<LI>The list of directories specified with the <TT>-J</TT> option.
The directories are searched in the order that they are specified
in the command line.
</LI>
</OL>
Baseclasses and regression classes may also be loaded using the 
<TT>-H</TT> option.

  
<HR>
<ADDRESS>
<A HREF=http://htk.eng.cam.ac.uk/docs/docs.shtml TARGET=_top>Back to HTK site</A><BR>See front page for HTK Authors
</ADDRESS>
</BODY>
</HTML>
