<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN">

<!--Converted with jLaTeX2HTML 2002 (1.62) JA patch-1.4
patched version by:  Kenshi Muto, Debian Project.
LaTeX2HTML 2002 (1.62),
original version by:  Nikos Drakos, CBLU, University of Leeds
* revised and updated by:  Marcus Hennecke, Ross Moore, Herb Swan
* with significant contributions from:
  Jens Lippmann, Marek Rouchal, Martin Wilck and others -->
<HTML>
<HEAD>
<TITLE>Contents of Model Adaptation using MAP</TITLE>
<META NAME="description" CONTENT="Contents of Model Adaptation using MAP">
<META NAME="keywords" CONTENT="htkbook">
<META NAME="resource-type" CONTENT="document">
<META NAME="distribution" CONTENT="global">

<META HTTP-EQUIV="Content-Type" CONTENT="text/html; charset=iso-8859-1">
<META NAME="Generator" CONTENT="jLaTeX2HTML v2002 JA patch-1.4">
<META HTTP-EQUIV="Content-Style-Type" CONTENT="text/css">

<LINK REL="STYLESHEET" HREF="htkbook.css">

<LINK REL="next" HREF="node139_mn.html">
<LINK REL="previous" HREF="node137_mn.html">
<LINK REL="up" HREF="node125_mn.html">
<LINK REL="next" HREF="node139_mn.html">
</HEAD>
 
<BODY bgcolor="#ffffff" text="#000000" link="#9944EE" vlink="#0000ff" alink="#00ff00">

<H1><A NAME="SECTION03630000000000000000">&#160;</A><A NAME="s:mapadapt">&#160;</A>
<BR>
Model Adaptation using MAP
</H1>

<P>
Model adaptation can also be accomplished using a maximum a
posteriori (MAP) approach<A NAME="15972">&#160;</A>. 
This adaptation process is sometimes
referred to as Bayesian adaptation. MAP adaptation involves the use 
of prior knowledge about the model parameter distribution.
Hence, if we know what the parameters of the model are
likely to be (before observing any adaptation data) using the prior
knowledge, we might well be able to make good use of the limited
adaptation data, to obtain a decent MAP estimate. This type of prior
is often termed an informative prior.
Note that if the prior
distribution indicates no preference as to what the model parameters
are likely to be (a non-informative prior), then the MAP estimate
obtained will be identical to that obtained using a maximum likelihood
approach.

<P>
For MAP adaptation purposes, the informative priors that are generally
used are the speaker independent model parameters. For mathematical
tractability conjugate priors are used, which results in a simple
adaptation formula. The update formula for a 
single stream system for state <SPAN CLASS="MATH"><IMG
 WIDTH="12" HEIGHT="28" ALIGN="MIDDLE" BORDER="0"
 SRC="img16.png"
 ALT="$ j$"></SPAN> and mixture component <SPAN CLASS="MATH"><IMG
 WIDTH="18" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img43.png"
 ALT="$ m$"></SPAN> is

<P>

<P></P>
<DIV ALIGN="CENTER" CLASS="mathdisplay"><A NAME="e:meanmap">&#160;</A><!-- MATH
 \begin{equation}
\hat{{\mbox{\boldmath$\mu$}}}_{jm} = \frac{ N_{jm} } { N_{jm} + \tau } \bar{{\mbox{\boldmath$\mu$}}}_{jm} +
                      \frac{ \tau } { N_{jm} + \tau } {\mbox{\boldmath$\mu$}}_{jm}
\end{equation}
 -->
<TABLE CLASS="equation" CELLPADDING="0" WIDTH="100%" ALIGN="CENTER">
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="CENTER"><SPAN CLASS="MATH"><IMG
 WIDTH="258" HEIGHT="51" ALIGN="MIDDLE" BORDER="0"
 SRC="img368.png"
 ALT="$\displaystyle \hat{{\mbox{\boldmath$\mu$}}}_{jm} = \frac{ N_{jm} } { N_{jm} + \...
...ath$\mu$}}}_{jm} + \frac{ \tau } { N_{jm} + \tau } {\mbox{\boldmath$\mu$}}_{jm}$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="arabic">9</SPAN>.<SPAN CLASS="arabic">7</SPAN>)</TD></TR>
</TABLE></DIV>
<BR CLEAR="ALL"><P></P>

<P>
where <SPAN CLASS="MATH"><IMG
 WIDTH="13" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img369.png"
 ALT="$ \tau$"></SPAN> is a weighting of the a priori knowledge to the
adaptation speech data and <SPAN CLASS="MATH"><IMG
 WIDTH="19" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img60.png"
 ALT="$ N$"></SPAN> is the occupation likelihood of the
adaptation data, defined as,
<!-- MATH
 \begin{displaymath}
N_{jm} =
                  \sum_{r=1}^R  \sum_{t=1}^{T_r} L^r_{jm}(t)
\end{displaymath}
 -->
<P></P>
<DIV ALIGN="CENTER" CLASS="mathdisplay">
<IMG
 WIDTH="154" HEIGHT="66" ALIGN="MIDDLE" BORDER="0"
 SRC="img370.png"
 ALT="$\displaystyle N_{jm} =
\sum_{r=1}^R \sum_{t=1}^{T_r} L^r_{jm}(t)
$">
</DIV><P></P>

<P>
where <!-- MATH
 ${\mbox{\boldmath $\mu$}}_{jm}$
 -->
<SPAN CLASS="MATH"><IMG
 WIDTH="33" HEIGHT="28" ALIGN="MIDDLE" BORDER="0"
 SRC="img371.png"
 ALT="$ {\mbox{\boldmath $\mu$}}_{jm}$"></SPAN> is the speaker independent mean 
and <!-- MATH
 $\bar{{\mbox{\boldmath $\mu$}}}_{jm}$
 -->
<SPAN CLASS="MATH"><IMG
 WIDTH="33" HEIGHT="28" ALIGN="MIDDLE" BORDER="0"
 SRC="img372.png"
 ALT="$ \bar{{\mbox{\boldmath $\mu$}}}_{jm}$"></SPAN> is the mean of the observed adaptation
data and is defined as,
<!-- MATH
 \begin{displaymath}
\bar{{\mbox{\boldmath$\mu$}}}_{jm} = \frac{
                  \sum_{r=1}^R  \sum_{t=1}^{T_r} L^r_{jm}(t)
{\mbox{\boldmath$o$}}^r_{t}}{
                  \sum_{r=1}^R  \sum_{t=1}^{T_r} L^r_{jm}(t)
}
\end{displaymath}
 -->
<P></P>
<DIV ALIGN="CENTER" CLASS="mathdisplay">
<IMG
 WIDTH="205" HEIGHT="64" ALIGN="MIDDLE" BORDER="0"
 SRC="img373.png"
 ALT="$\displaystyle \bar{{\mbox{\boldmath$\mu$}}}_{jm} = \frac{
\sum_{r=1}^R \sum_{t=...
...}(t)
{\mbox{\boldmath$o$}}^r_{t}}{
\sum_{r=1}^R \sum_{t=1}^{T_r} L^r_{jm}(t)
}
$">
</DIV><P></P>

<P>
As can be seen, if the occupation likelihood
of a Gaussian component (<SPAN CLASS="MATH"><IMG
 WIDTH="35" HEIGHT="29" ALIGN="MIDDLE" BORDER="0"
 SRC="img374.png"
 ALT="$ N_{jm}$"></SPAN>) is small, then the
mean MAP estimate will remain close to the speaker
independent component mean. 
With MAP adaptation, every single mean
component in the system is updated with a MAP estimate, based on the
prior mean, the weighting and the adaptation data. Hence, MAP
adaptation requires a new ``speaker-dependent'' model set to be saved.

<P>
One obvious drawback to MAP adaptation is that it requires more
adaptation data to be effective when compared to MLLR, because MAP
adaptation is specifically defined at the component level. When
larger amounts of adaptation training data become available, MAP
begins to perform better than MLLR, due to this detailed update of
each component (rather than the pooled Gaussian transformation
approach of MLLR). In fact the two adaptation processes can be
combined to improve performance still further, by using the MLLR
transformed means as the priors for MAP adaptation (by replacing
<!-- MATH
 ${\mbox{\boldmath $\mu$}}_{jm}$
 -->
<SPAN CLASS="MATH"><IMG
 WIDTH="33" HEIGHT="28" ALIGN="MIDDLE" BORDER="0"
 SRC="img371.png"
 ALT="$ {\mbox{\boldmath $\mu$}}_{jm}$"></SPAN> in equation&nbsp;<A HREF="node138_ct.html#e:meanmap">9.7</A> with the transformed mean
of equation&nbsp;<A HREF="node128_ct.html#e:mtrans">9.1</A>). In this case
components that have a low occupation likelihood in the adaptation
data, (and hence would not change much using MAP alone) have been
adapted using a regression class transform in MLLR. An example usage
is shown in the following section. 

<P>

<HR>
<ADDRESS>
<A HREF=http://htk.eng.cam.ac.uk/docs/docs.shtml TARGET=_top>Back to HTK site</A><BR>See front page for HTK Authors
</ADDRESS>
</BODY>
</HTML>
