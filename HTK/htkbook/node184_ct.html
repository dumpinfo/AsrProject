<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN">

<!--Converted with jLaTeX2HTML 2002 (1.62) JA patch-1.4
patched version by:  Kenshi Muto, Debian Project.
LaTeX2HTML 2002 (1.62),
original version by:  Nikos Drakos, CBLU, University of Leeds
* revised and updated by:  Marcus Hennecke, Ross Moore, Herb Swan
* with significant contributions from:
  Jens Lippmann, Marek Rouchal, Martin Wilck and others -->
<HTML>
<HEAD>
<TITLE>Contents of Estimating probabilities</TITLE>
<META NAME="description" CONTENT="Contents of Estimating probabilities">
<META NAME="keywords" CONTENT="htkbook">
<META NAME="resource-type" CONTENT="document">
<META NAME="distribution" CONTENT="global">

<META HTTP-EQUIV="Content-Type" CONTENT="text/html; charset=iso-8859-1">
<META NAME="Generator" CONTENT="jLaTeX2HTML v2002 JA patch-1.4">
<META HTTP-EQUIV="Content-Style-Type" CONTENT="text/css">

<LINK REL="STYLESHEET" HREF="htkbook.css">

<LINK REL="next" HREF="node187_mn.html">
<LINK REL="previous" HREF="node183_mn.html">
<LINK REL="up" HREF="node183_mn.html">
<LINK REL="next" HREF="node185_mn.html">
</HEAD>
 
<BODY bgcolor="#ffffff" text="#000000" link="#9944EE" vlink="#0000ff" alink="#00ff00">

<H2><A NAME="SECTION04131000000000000000">&#160;</A><A NAME="s:HLMdiscounts">&#160;</A><A NAME="discounting_and_other_fun_things">&#160;</A>
<BR>
Estimating probabilities
</H2>
Language models seek to estimate the probability of each possible word
sequence event occurring. In order to calculate maximum likelihood
estimates this set of events must be finite so that the language model
can ensure that the sum of the probabilities of all events is 1 given
some context. In an <SPAN CLASS="MATH"><IMG
 WIDTH="14" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img1.png"
 ALT="$ n$"></SPAN>-gram model the combination of the finite vocabulary
and fixed length history limits the number of unique events to
<!-- MATH
 $|\mathbb{W}|^n$
 -->
<SPAN CLASS="MATH"><IMG
 WIDTH="38" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img495.png"
 ALT="$ \vert\mathbb{W}\vert^n$"></SPAN>.  For any <SPAN CLASS="MATH"><IMG
 WIDTH="43" HEIGHT="28" ALIGN="MIDDLE" BORDER="0"
 SRC="img558.png"
 ALT="$ n&gt;1$"></SPAN> it is highly unlikely that all word
sequence events will be encountered in the training corpora, and many
that do occur may only appear one or two times. A language model
should not give any unseen event zero probability,<A NAME="tex2html64" HREF="footnode_mn.html#foot21737" TARGET="footer"><SUP><SPAN CLASS="arabic">14</SPAN>.<SPAN CLASS="arabic">11</SPAN></SUP></A> but without an infinite
quantity of training text it is almost certain that there will be
events it does not encounter during training, so various mechanisms
have been developed to redistribute probability within the model such that these
unseen events are given some non-zero probability. 
<P>
As in equation <A HREF="node178_ct.html#ngramcountdiv">14.3</A>, the maximum likelihood estimate of
the probability of an event <!-- MATH
 $\mathcal{A}$
 -->
<SPAN CLASS="MATH"><IMG
 WIDTH="17" HEIGHT="15" ALIGN="BOTTOM" BORDER="0"
 SRC="img559.png"
 ALT="$ \mathcal{A}$"></SPAN> occurring is defined by the
number of times that event is observed, <SPAN CLASS="MATH"><IMG
 WIDTH="12" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img560.png"
 ALT="$ a$"></SPAN>, and the total number of
samples in the training set of all observations, <SPAN CLASS="MATH"><IMG
 WIDTH="16" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img194.png"
 ALT="$ A$"></SPAN>, where
<!-- MATH
 $P(\mathcal{A}) = \frac{a}{A}$
 -->
<SPAN CLASS="MATH"><IMG
 WIDTH="76" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img561.png"
 ALT="$ P(\mathcal{A}) = \frac{a}{A}$"></SPAN>.  With this definition, events that do
not occur in the training data are assigned zero probability since it
will be the case that <SPAN CLASS="MATH"><IMG
 WIDTH="42" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img562.png"
 ALT="$ a=0$"></SPAN>.  [Katz 1987]<A NAME="tex2html65" HREF="footnode_mn.html#foot21738" TARGET="footer"><SUP><SPAN CLASS="arabic">14</SPAN>.<SPAN CLASS="arabic">12</SPAN></SUP></A> suggests multiplying each observed count by a discount
coefficient factor, <SPAN CLASS="MATH"><IMG
 WIDTH="20" HEIGHT="29" ALIGN="MIDDLE" BORDER="0"
 SRC="img563.png"
 ALT="$ d_a$"></SPAN>, which is dependent upon the number of times
the event is observed, <SPAN CLASS="MATH"><IMG
 WIDTH="12" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img560.png"
 ALT="$ a$"></SPAN>, such that <!-- MATH
 $a' = d_a \,.\, a$
 -->
<SPAN CLASS="MATH"><IMG
 WIDTH="72" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img564.png"
 ALT="$ a' = d_a  .  a$"></SPAN>.
Using this discounted occurrence count, the probability of an event
that occurs <SPAN CLASS="MATH"><IMG
 WIDTH="12" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img560.png"
 ALT="$ a$"></SPAN> times now becomes
<!-- MATH
 $P_\mathrm{discount}(\mathcal{A}) = \frac{a'}{A\,}$
 -->
<SPAN CLASS="MATH"><IMG
 WIDTH="123" HEIGHT="38" ALIGN="MIDDLE" BORDER="0"
 SRC="img565.png"
 ALT="$ P_\mathrm{discount}(\mathcal{A}) = \frac{a'}{A }$"></SPAN>.
Different discounting schemes have been proposed that define the
discount coefficient, <SPAN CLASS="MATH"><IMG
 WIDTH="20" HEIGHT="29" ALIGN="MIDDLE" BORDER="0"
 SRC="img563.png"
 ALT="$ d_a$"></SPAN>, in specific ways. The same discount
coefficient is used for all events that occur the same number of
times on the basis of the symmetry requirement that two events that
occur with equal frequency, <SPAN CLASS="MATH"><IMG
 WIDTH="12" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img560.png"
 ALT="$ a$"></SPAN>, must have the same probability, <SPAN CLASS="MATH"><IMG
 WIDTH="20" HEIGHT="28" ALIGN="MIDDLE" BORDER="0"
 SRC="img566.png"
 ALT="$ p_a$"></SPAN>.

<P>
Defining <SPAN CLASS="MATH"><IMG
 WIDTH="19" HEIGHT="28" ALIGN="MIDDLE" BORDER="0"
 SRC="img567.png"
 ALT="$ c_a$"></SPAN> as the number of events that occur exactly <SPAN CLASS="MATH"><IMG
 WIDTH="12" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img560.png"
 ALT="$ a$"></SPAN> times
such that <!-- MATH
 $A = \sum_{a\ge 1} a\,.\,c_a$
 -->
<SPAN CLASS="MATH"><IMG
 WIDTH="113" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img568.png"
 ALT="$ A = \sum_{a\ge 1} a . c_a$"></SPAN> it follows that the total amount of
reserved mass, left over for distribution amongst the unseen events,
is 
<!-- MATH
 $\frac{1}{c_0} \; ( 1\;-$
 -->
<SPAN CLASS="MATH"><IMG
 WIDTH="55" HEIGHT="34" ALIGN="MIDDLE" BORDER="0"
 SRC="img569.png"
 ALT="$ \frac{1}{c_0} \; ( 1\;-$"></SPAN> <!-- MATH
 $\frac{1}{A}\sum_{a\ge 1}$
 -->
<SPAN CLASS="MATH"><IMG
 WIDTH="61" HEIGHT="34" ALIGN="MIDDLE" BORDER="0"
 SRC="img570.png"
 ALT="$ \frac{1}{A}\sum_{a\ge 1}$"></SPAN> <!-- MATH
 $d_a\,.\,c_a\,.\,a)$
 -->
<SPAN CLASS="MATH"><IMG
 WIDTH="69" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img571.png"
 ALT="$ d_a . c_a . a)$"></SPAN>.

<P>
<BR><HR>
<!--Table of Child-Links-->
<A NAME="CHILD_LINKS"><STRONG>Subsections</STRONG></A>

<UL CLASS="ChildLinks">
<LI><A NAME="tex2html3853" HREF="node185_mn.html" TARGET="main"><SMALL>Good-Turing discounting</SMALL></A>
<LI><A NAME="tex2html3854" HREF="node186_mn.html" TARGET="main"><SMALL>Absolute discounting</SMALL></A>
</UL>
<!--End of Table of Child-Links-->

<HR>
<ADDRESS>
<A HREF=http://htk.eng.cam.ac.uk/docs/docs.shtml TARGET=_top>Back to HTK site</A><BR>See front page for HTK Authors
</ADDRESS>
</BODY>
</HTML>
