<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN">

<!--Converted with jLaTeX2HTML 2002 (1.62) JA patch-1.4
patched version by:  Kenshi Muto, Debian Project.
LaTeX2HTML 2002 (1.62),
original version by:  Nikos Drakos, CBLU, University of Leeds
* revised and updated by:  Marcus Hennecke, Ross Moore, Herb Swan
* with significant contributions from:
  Jens Lippmann, Marek Rouchal, Martin Wilck and others -->
<HTML>
<HEAD>
<TITLE>Contents of Adaptive Training with Linear Transforms</TITLE>
<META NAME="description" CONTENT="Contents of Adaptive Training with Linear Transforms">
<META NAME="keywords" CONTENT="htkbook">
<META NAME="resource-type" CONTENT="document">
<META NAME="distribution" CONTENT="global">

<META HTTP-EQUIV="Content-Type" CONTENT="text/html; charset=iso-8859-1">
<META NAME="Generator" CONTENT="jLaTeX2HTML v2002 JA patch-1.4">
<META HTTP-EQUIV="Content-Style-Type" CONTENT="text/css">

<LINK REL="STYLESHEET" HREF="htkbook.css">

<LINK REL="next" HREF="node138_mn.html">
<LINK REL="previous" HREF="node126_mn.html">
<LINK REL="up" HREF="node125_mn.html">
<LINK REL="next" HREF="node138_mn.html">
</HEAD>
 
<BODY bgcolor="#ffffff" text="#000000" link="#9944EE" vlink="#0000ff" alink="#00ff00">

<H1><A NAME="SECTION03620000000000000000">&#160;</A><A NAME="s:adapttrain">&#160;</A>
<BR>
Adaptive Training with Linear Transforms
</H1>

In order to improve the performance of systems when there are multiple
speakers, or acoustic environments, present in the training corpus 
adaptive training may be used. Here, rather than using adaptation
transformations only during test, adaptation transforms are estimated
for each training speaker. The model, sometimes referred to as a <EM>canonical
model</EM>, is then estimated given the set of speaker transforms. In the
same fashion as standard training, the whole process can then be repeated.

<P>
In the current implementation, adaptive training is only supported
with constrained MLLR as the transform for each speaker. As CMLLR is
implemented as one, or more, feature-space transformations. The
estimation formulae in section&nbsp;<A HREF="node120_ct.html#s:bwformulae">8.8</A> are simplified
modified to accumulate statistics using
<!-- MATH
 ${\mbox{\boldmath $A$}}^{(i)}{\mbox{\boldmath $o$}}+{\mbox{\boldmath $b$}}^{(i)}$
 -->
<SPAN CLASS="MATH"><IMG
 WIDTH="85" HEIGHT="38" ALIGN="MIDDLE" BORDER="0"
 SRC="img366.png"
 ALT="$ {\mbox{\boldmath $A$}}^{(i)}{\mbox{\boldmath $o$}}+{\mbox{\boldmath $b$}}^{(i)}$"></SPAN> for all the data from speaker <SPAN CLASS="MATH"><IMG
 WIDTH="10" HEIGHT="15" ALIGN="BOTTOM" BORDER="0"
 SRC="img10.png"
 ALT="$ i$"></SPAN>
rather than <!-- MATH
 ${\mbox{\boldmath $o$}}$
 -->
<SPAN CLASS="MATH"><IMG
 WIDTH="13" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img48.png"
 ALT="$ {\mbox{\boldmath $o$}}$"></SPAN>. The update formula for <!-- MATH
 ${\mbox{\boldmath $\mu$}}_{jsm}$
 -->
<SPAN CLASS="MATH"><IMG
 WIDTH="39" HEIGHT="28" ALIGN="MIDDLE" BORDER="0"
 SRC="img266.png"
 ALT="$ {\mbox{\boldmath $\mu$}}_{jsm}$"></SPAN> then
becomes
 
<!-- MATH
 \begin{displaymath}
\hat{{\mbox{\boldmath$\mu$}}}_{jsm} = \frac{
                  \sum_{i=1}^I\sum_{r=1}^{R^i}  \sum_{t=1}^{T_r} L^r_{jsm}(t)
({\mbox{\boldmath$A$}}^{(i)}{\mbox{\boldmath$o$}}^r_{st}+{\mbox{\boldmath$b$}}^{(i)})}{
                  \sum_{i=1}^I\sum_{r=1}^{R^i}  \sum_{t=1}^{T_r} L^r_{jsm}(t)
}
\end{displaymath}
 -->
<P></P>
<DIV ALIGN="CENTER" CLASS="mathdisplay">
<IMG
 WIDTH="347" HEIGHT="69" ALIGN="MIDDLE" BORDER="0"
 SRC="img367.png"
 ALT="$\displaystyle \hat{{\mbox{\boldmath$\mu$}}}_{jsm} = \frac{
\sum_{i=1}^I\sum_{r=...
...ath$b$}}^{(i)})}{
\sum_{i=1}^I\sum_{r=1}^{R^i} \sum_{t=1}^{T_r} L^r_{jsm}(t)
}
$">
</DIV><P></P>

<P>
Specifying that adaptive training is to be used simply requires specifying
the parent transform that the model set should be built on. Note that usually
the parent transform will also be used as an input transform.

<P>

<HR>
<ADDRESS>
<A HREF=http://htk.eng.cam.ac.uk/docs/docs.shtml TARGET=_top>Back to HTK site</A><BR>See front page for HTK Authors
</ADDRESS>
</BODY>
</HTML>
